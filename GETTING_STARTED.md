# Getting Started with JudgmentAI

This guide walks you through setting up JudgmentAI from scratch.

## What You've Built

**JudgmentAI** is a complete backend system for:
- ğŸ” Scraping Reddit discussions
- ğŸ§  Analyzing sentiment at aspect-level (not just positive/negative)
- ğŸ’¬ Chatting with AI that has context from Reddit insights
- ğŸ” User authentication and authorization
- âš¡ Asynchronous background processing

## Architecture Highlights

### Modular Design
Every component is isolated for maintainability:
- `api/` - HTTP endpoints
- `core/` - Configuration, security
- `db/` - Database schemas and connection
- `services/` - Business logic
- `tasks/` - Background workers

### Key Design Decisions

1. **Stateless Chat Engine**
   - âŒ NOT a global chat object (causes data leaks)
   - âœ… Fetches history per request, passes to LLM
   - Why: Prevents users seeing each other's conversations

2. **Celery for Heavy Tasks**
   - âŒ NOT FastAPI BackgroundTasks (blocks server)
   - âœ… Separate worker processes
   - Why: API stays responsive while scraping 1000s of comments

3. **ABSA over Basic Sentiment**
   - âŒ NOT "this review is 60% positive"
   - âœ… "Camera: positive, Battery: negative"
   - Why: Nuanced insights users actually want

## Setup Steps

### 1. Supabase Setup (5 minutes)

1. Go to [supabase.com](https://supabase.com) and create a project
2. Go to **Database** â†’ **Extensions** â†’ Enable `vector`
3. Go to **SQL Editor** â†’ Copy/paste from `backend/app/db/init_db.sql` â†’ Run
4. Go to **Settings** â†’ **API** â†’ Copy:
   - Project URL
   - `anon` key
   - `service_role` key

### 2. Reddit API Credentials (3 minutes)

1. Go to [reddit.com/prefs/apps](https://reddit.com/prefs/apps)
2. Click "create app" or "create another app"
3. Choose "script"
4. Name: "JudgmentAI"
5. Redirect URI: `http://localhost:8000`
6. Copy:
   - Client ID (under app name)
   - Client Secret

### 3. OpenAI API Key (2 minutes)

1. Go to [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
2. Create new secret key
3. Copy it (you won't see it again!)

### 4. Backend Setup

```bash
cd backend

# Option A: Automated setup
make setup
# Edit .env with your keys
make dev

# In another terminal
make celery

# Option B: Docker (recommended)
cp .env.example .env
# Edit .env with your keys
docker-compose up
```

### 5. Test the API

Open http://localhost:8000/docs

Try:
1. **POST /api/v1/auth/signup** - Create account
2. **POST /api/v1/auth/login** - Get JWT token
3. **POST /api/v1/scrape** - Scrape a Reddit URL
4. **POST /api/v1/chat** - Ask about the insights

## Understanding the Flow

### Scraping Flow
```
User â†’ POST /api/v1/scrape â†’ FastAPI
                             â†“
                       Celery Task Queued
                             â†“
            Celery Worker â† Redis (broker)
                 â†“
         1. Scrape Reddit (PRAW)
         2. Extract aspects (spaCy)
         3. Classify sentiment (SetFit)
         4. Generate embeddings (OpenAI)
         5. Store in Supabase (pgvector)
                 â†“
              Done!
```

### Chat Flow
```
User â†’ POST /api/v1/chat â†’ FastAPI
                            â†“
                    Fetch user's chat history
                            â†“
                    Query vector store (pgvector)
                    "Find insights similar to user's question"
                            â†“
                    LlamaIndex retrieves top 5 insights
                            â†“
                    Build prompt:
                    - System: "You are JudgmentAI..."
                    - Context: [retrieved insights]
                    - History: [past messages]
                    - User: [current question]
                            â†“
                    OpenAI GPT-4o-mini
                            â†“
                    Save user message + AI response
                            â†“
                    Return to user
```

## Project Structure

```
JudgmentAI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/          # 3 routers: auth, chat, scrape
â”‚   â”‚   â”œâ”€â”€ core/            # config, security, dependencies
â”‚   â”‚   â”œâ”€â”€ db/              # schemas, SQL, Supabase client
â”‚   â”‚   â”œâ”€â”€ services/        # chat_service, analysis_service
â”‚   â”‚   â”œâ”€â”€ tasks/           # celery_app, reddit_scraper, web_search
â”‚   â”‚   â”œâ”€â”€ utils/           # helpers
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI app
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ Makefile
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ plan.md                  # Original architecture plan
â””â”€â”€ README.md                # This file
```

## Common Commands

```bash
# Development
make dev          # Start FastAPI server
make celery       # Start background workers
make format       # Format code with black
make lint         # Check code quality
make test         # Run tests

# Docker
docker-compose up           # Start all services
docker-compose logs -f      # View logs
docker-compose down         # Stop services

# Production
APP_ENV=production uvicorn app.main:app --workers 4
celery -A app.tasks.celery_app worker --concurrency=4
```

## Next Steps

1. **Test End-to-End**
   - Signup â†’ Login â†’ Scrape a Reddit URL â†’ Chat about it

2. **Build Frontend** (Phase 5)
   - React + TailwindCSS
   - Chat interface
   - Task status monitoring

3. **Optimize Scraping** (Phase 6)
   - Implement morechildren API for full threads
   - Add caching to avoid re-scraping

4. **Deploy** (Phase 7)
   - Railway/Render for FastAPI
   - Upstash for Redis
   - Vercel for frontend

## Troubleshooting

**"No module named 'app'"**
- Make sure you're in the `backend/` directory
- Virtual environment activated

**"Connection refused" to Supabase**
- Check `.env` has correct `SUPABASE_URL`
- Project not paused in Supabase dashboard

**Celery tasks stuck "pending"**
- Check Redis is running: `redis-cli ping` should return `PONG`
- Check Celery worker is running
- Check `CELERY_BROKER_URL` in `.env`

**"vector extension not found"**
- Go to Supabase â†’ Database â†’ Extensions
- Enable `vector`
- Re-run init_db.sql

## Resources

- [FastAPI Docs](https://fastapi.tiangolo.com)
- [LlamaIndex Docs](https://docs.llamaindex.ai)
- [Celery Docs](https://docs.celeryq.dev)
- [Supabase Docs](https://supabase.com/docs)
- [PRAW Docs](https://praw.readthedocs.io)

## Questions?

Check the detailed plan: [plan.md](plan.md)

---

Built with â¤ï¸ following clean architecture principles.
